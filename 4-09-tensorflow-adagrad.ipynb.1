{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>TensorFlow による推奨コーディングの作法</h2>\n",
       "<ul>\n",
       "  <li>Inference : 「推論」に該当する部分。入力から、分類結果や回帰結果を予想する部分。</li>\n",
       "  <li>Loss : 「目標値との誤差」に該当する部分。最適化したい値。→　adagrad　使用</li>\n",
       "  <li>Training: 最適化のアルゴリズム。</li>\n",
       "</ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<h2>TensorFlow による推奨コーディングの作法</h2>\n",
    "<ul>\n",
    "  <li>Inference : 「推論」に該当する部分。入力から、分類結果や回帰結果を予想する部分。</li>\n",
    "  <li>Loss : 「目標値との誤差」に該当する部分。最適化したい値。→　adagrad　使用</li>\n",
    "  <li>Training: 最適化のアルゴリズム。</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  validation loss: 0.640931  validation accuracy: 0.7725\n",
      "epoch: 1  validation loss: 0.348463  validation accuracy: 0.8975\n",
      "epoch: 2  validation loss: 0.284775  validation accuracy: 0.91475\n",
      "epoch: 3  validation loss: 0.230161  validation accuracy: 0.933\n",
      "epoch: 4  validation loss: 0.2227  validation accuracy: 0.935\n",
      "epoch: 5  validation loss: 0.199533  validation accuracy: 0.94125\n",
      "epoch: 6  validation loss: 0.183117  validation accuracy: 0.94625\n",
      "epoch: 7  validation loss: 0.175447  validation accuracy: 0.952\n",
      "epoch: 8  validation loss: 0.171852  validation accuracy: 0.952\n",
      "epoch: 9  validation loss: 0.178914  validation accuracy: 0.95125\n",
      "epoch: 10  validation loss: 0.171535  validation accuracy: 0.95225\n",
      "epoch: 11  validation loss: 0.161454  validation accuracy: 0.95775\n",
      "epoch: 12  validation loss: 0.157893  validation accuracy: 0.95525\n",
      "epoch: 13  validation loss: 0.15491  validation accuracy: 0.9585\n",
      "epoch: 14  validation loss: 0.157005  validation accuracy: 0.957\n",
      "epoch: 15  validation loss: 0.152632  validation accuracy: 0.95975\n",
      "epoch: 16  validation loss: 0.142753  validation accuracy: 0.96275\n",
      "epoch: 17  validation loss: 0.138978  validation accuracy: 0.96475\n",
      "epoch: 18  validation loss: 0.14384  validation accuracy: 0.964\n",
      "epoch: 19  validation loss: 0.149123  validation accuracy: 0.962\n",
      "epoch: 20  validation loss: 0.157463  validation accuracy: 0.963\n",
      "epoch: 21  validation loss: 0.144662  validation accuracy: 0.96375\n",
      "epoch: 22  validation loss: 0.142993  validation accuracy: 0.96425\n",
      "epoch: 23  validation loss: 0.147566  validation accuracy: 0.96125\n",
      "epoch: 24  validation loss: 0.139972  validation accuracy: 0.9645\n",
      "epoch: 25  validation loss: 0.145299  validation accuracy: 0.96525\n",
      "epoch: 26  validation loss: 0.151733  validation accuracy: 0.9645\n",
      "epoch: 27  validation loss: 0.140458  validation accuracy: 0.96525\n",
      "epoch: 28  validation loss: 0.145218  validation accuracy: 0.96475\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "# 推論部\n",
    "#  x : データテンソル\n",
    "#  keep_prob : ドロップアウトしない率\n",
    "#  n_in : 入力次元数\n",
    "#  n_hiddens : 隠れ次元数のリスト\n",
    "#  n_out : 出力次元数\n",
    "def inference(x, keep_prob, n_in, n_hiddens, n_out):\n",
    "    # 重みの初期化\n",
    "    def weight_variable(shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.zeros(shape)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    # 入力層 - 隠れ層、隠れ層 - 隠れ層\n",
    "    for i, n_hidden in enumerate(n_hiddens):\n",
    "        if i == 0:\n",
    "            input = x\n",
    "            input_dim = n_in\n",
    "        else:\n",
    "            input = output\n",
    "            input_dim = n_hiddens[i-1]\n",
    "\n",
    "        W = weight_variable([input_dim, n_hidden])\n",
    "        b = bias_variable([n_hidden])\n",
    "\n",
    "        h = tf.nn.relu(tf.matmul(input, W) + b)\n",
    "        output = tf.nn.dropout(h, keep_prob)\n",
    "\n",
    "    # 隠れ層 - 出力層\n",
    "    W_out = weight_variable([n_hiddens[-1], n_out])\n",
    "    b_out = bias_variable([n_out])\n",
    "    y = tf.nn.softmax(tf.matmul(output, W_out) + b_out)\n",
    "    return y\n",
    "\n",
    "# 誤差関数\n",
    "def loss(y, t):\n",
    "    cross_entropy = \\\n",
    "        tf.reduce_mean(-tf.reduce_sum(\n",
    "                       t * tf.log(tf.clip_by_value(y, 1e-10, 1.0)),\n",
    "                       reduction_indices=[1]))\n",
    "    return cross_entropy\n",
    "\n",
    "# 最適化学習部\n",
    "def training(loss):\n",
    "#    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    optimizer = tf.train.AdagradOptimizer(0.01)\n",
    "    train_step = optimizer.minimize(loss)\n",
    "    return train_step\n",
    "\n",
    "# 検証\n",
    "def accuracy(y, t):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(t, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "データの生成\n",
    "'''\n",
    "mnist = datasets.fetch_mldata('MNIST original', data_home='.')\n",
    "\n",
    "n = len(mnist.data)\n",
    "N = 30000  # MNISTの一部を使う\n",
    "N_train = 20000\n",
    "N_validation = 4000\n",
    "indices = np.random.permutation(range(n))[:N]  # ランダムにN枚を選択\n",
    "\n",
    "X = mnist.data[indices]\n",
    "y = mnist.target[indices]\n",
    "Y = np.eye(10)[y.astype(int)]  # 1-of-K 表現に変換\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = \\\n",
    "    train_test_split(X, Y, train_size=N_train)\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = \\\n",
    "    train_test_split(X_train, Y_train, test_size=N_validation)\n",
    "\n",
    "'''\n",
    "モデル設定\n",
    "'''\n",
    "n_in = len(X[0])\n",
    "n_hiddens = [200, 200, 200]  # 各隠れ層の次元数\n",
    "n_out = len(Y[0])\n",
    "p_keep = 0.5\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, n_in])\n",
    "t = tf.placeholder(tf.float32, shape=[None, n_out])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "y = inference(x, keep_prob, n_in=n_in, n_hiddens=n_hiddens, n_out=n_out)\n",
    "loss = loss(y, t)\n",
    "train_step = training(loss)\n",
    "\n",
    "accuracy = accuracy(y, t)\n",
    "\n",
    "history = {\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "'''\n",
    "モデル学習\n",
    "'''\n",
    "epochs = 50\n",
    "batch_size = 200\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "n_batches = N_train // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    X_, Y_ = shuffle(X_train, Y_train)\n",
    "\n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        sess.run(train_step, feed_dict={\n",
    "            x: X_[start:end],\n",
    "            t: Y_[start:end],\n",
    "            keep_prob: p_keep\n",
    "        })\n",
    "\n",
    "    # 検証データを用いた評価\n",
    "    val_loss = loss.eval(session=sess, feed_dict={\n",
    "        x: X_validation,\n",
    "        t: Y_validation,\n",
    "        keep_prob: 1.0\n",
    "    })\n",
    "    val_acc = accuracy.eval(session=sess, feed_dict={\n",
    "        x: X_validation,\n",
    "        t: Y_validation,\n",
    "        keep_prob: 1.0\n",
    "    })\n",
    "\n",
    "    # 検証データに対する学習の進み具合を記録\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    print('epoch:', epoch,\n",
    "          ' validation loss:', val_loss,\n",
    "          ' validation accuracy:', val_acc)\n",
    "\n",
    "'''\n",
    "予測精度の評価\n",
    "'''\n",
    "accuracy_rate = accuracy.eval(session=sess, feed_dict={\n",
    "    x: X_test,\n",
    "    t: Y_test,\n",
    "    keep_prob: 1.0\n",
    "})\n",
    "print('accuracy: ', accuracy_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "学習の進み具合を可視化\n",
    "'''\n",
    "plt.rc('font', family='serif')\n",
    "fig = plt.figure()\n",
    "plt.subplot(2, 1, 1)\n",
    "#plt.plot(range(epochs), history['val_acc'], label='acc', color='black')\n",
    "plt.plot(range(epochs), history['val_loss'], label='loss', color='gray')\n",
    "\n",
    "plt.title('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rc('font', family='serif')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(range(epochs), history['val_acc'], label='acc', color='black')\n",
    "\n",
    "plt.title('accurary')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
