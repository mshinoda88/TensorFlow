{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>TensorFlow による実装 ：手書きの数字の画像データ判定<br>\n",
       "活性化関数：Parametric ReLU<br>\n",
       "隠れ層：3層<br>\n",
       "</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<h2>TensorFlow による実装 ：手書きの数字の画像データ判定<br>\n",
    "活性化関数：Parametric ReLU<br>\n",
    "隠れ層：3層<br>\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 2.30228  accuracy: 0.117625\n",
      "epoch: 1  loss: 2.30184  accuracy: 0.11525\n",
      "epoch: 2  loss: 2.30136  accuracy: 0.11525\n",
      "epoch: 3  loss: 2.30083  accuracy: 0.11525\n",
      "epoch: 4  loss: 2.30017  accuracy: 0.11525\n",
      "epoch: 5  loss: 2.29934  accuracy: 0.11525\n",
      "epoch: 6  loss: 2.29821  accuracy: 0.11675\n",
      "epoch: 7  loss: 2.2965  accuracy: 0.130875\n",
      "epoch: 8  loss: 2.29363  accuracy: 0.193125\n",
      "epoch: 9  loss: 2.28792  accuracy: 0.2945\n",
      "epoch: 10  loss: 2.27343  accuracy: 0.23625\n",
      "epoch: 11  loss: 2.21921  accuracy: 0.11975\n",
      "epoch: 12  loss: 2.03735  accuracy: 0.2555\n",
      "epoch: 13  loss: 1.53864  accuracy: 0.384875\n",
      "epoch: 14  loss: 1.18119  accuracy: 0.55975\n",
      "epoch: 15  loss: 0.958215  accuracy: 0.65125\n",
      "epoch: 16  loss: 0.737435  accuracy: 0.77025\n",
      "epoch: 17  loss: 0.634292  accuracy: 0.801\n",
      "epoch: 18  loss: 0.561059  accuracy: 0.832375\n",
      "epoch: 19  loss: 0.574404  accuracy: 0.816375\n",
      "epoch: 20  loss: 0.476518  accuracy: 0.853\n",
      "epoch: 21  loss: 0.42995  accuracy: 0.874125\n",
      "epoch: 22  loss: 0.405787  accuracy: 0.87875\n",
      "epoch: 23  loss: 0.36289  accuracy: 0.90025\n",
      "epoch: 24  loss: 0.33545  accuracy: 0.907375\n",
      "epoch: 25  loss: 0.311458  accuracy: 0.90975\n",
      "epoch: 26  loss: 0.296248  accuracy: 0.916\n",
      "epoch: 27  loss: 0.260884  accuracy: 0.927375\n",
      "epoch: 28  loss: 0.240399  accuracy: 0.935125\n",
      "epoch: 29  loss: 0.259037  accuracy: 0.920625\n",
      "epoch: 30  loss: 0.201424  accuracy: 0.945\n",
      "epoch: 31  loss: 0.189419  accuracy: 0.9505\n",
      "epoch: 32  loss: 0.172938  accuracy: 0.9545\n",
      "epoch: 33  loss: 0.153976  accuracy: 0.9595\n",
      "epoch: 34  loss: 0.173677  accuracy: 0.950625\n",
      "epoch: 35  loss: 0.131964  accuracy: 0.96375\n",
      "epoch: 36  loss: 0.114528  accuracy: 0.971625\n",
      "epoch: 37  loss: 0.177019  accuracy: 0.958125\n",
      "epoch: 38  loss: 0.125062  accuracy: 0.966\n",
      "epoch: 39  loss: 0.114668  accuracy: 0.969875\n",
      "epoch: 40  loss: 0.0849318  accuracy: 0.981125\n",
      "epoch: 41  loss: 0.0778541  accuracy: 0.982125\n",
      "epoch: 42  loss: 0.0685854  accuracy: 0.98525\n",
      "epoch: 43  loss: 0.0835879  accuracy: 0.976125\n",
      "epoch: 44  loss: 0.0521542  accuracy: 0.99075\n",
      "epoch: 45  loss: 0.0488728  accuracy: 0.99075\n",
      "epoch: 46  loss: 0.0399749  accuracy: 0.993375\n",
      "epoch: 47  loss: 0.0418062  accuracy: 0.992625\n",
      "epoch: 48  loss: 0.0536635  accuracy: 0.985875\n",
      "epoch: 49  loss: 0.0338192  accuracy: 0.99475\n",
      "accuracy:  0.931\n",
      "[ -9.41298902e-03  -8.53842776e-03  -5.22275828e-03  -3.24158138e-03\n",
      "  -1.09962057e-02  -2.41602669e-04  -1.49254513e-03  -2.09203865e-02\n",
      "  -2.40208092e-03  -1.09233651e-02  -6.83593052e-03  -5.49631333e-03\n",
      "  -7.98264518e-03   9.19378072e-04  -9.01322998e-03  -3.16829642e-06\n",
      "  -8.09459575e-03  -1.66938845e-02  -1.46411185e-03  -1.20064255e-03\n",
      "  -1.20178855e-03  -4.06566402e-03  -9.11860447e-03  -1.25019746e-02\n",
      "  -1.92245170e-02  -3.84862302e-03  -1.90171469e-02  -4.15625283e-03\n",
      "  -2.62058638e-02  -2.21295777e-04  -9.12182964e-04  -9.58780851e-03\n",
      "  -5.51108085e-03  -1.50539819e-02  -2.51987297e-02  -3.34415329e-03\n",
      "  -5.98266581e-03   3.51641735e-04  -3.52946436e-03  -1.72572061e-02\n",
      "  -1.67048397e-03  -1.30432481e-02  -5.15721925e-03  -5.95135102e-03\n",
      "  -1.39018241e-03  -8.42734613e-03  -4.44532512e-03  -2.25443672e-03\n",
      "  -2.21039820e-02  -8.15598574e-03  -6.86705206e-03  -3.03586535e-02\n",
      "  -9.70120949e-04  -2.21770862e-03  -4.37230010e-05  -1.35604190e-02\n",
      "  -2.37182016e-03  -4.63680690e-03  -1.39512192e-03  -9.02351644e-03\n",
      "  -1.56093342e-02  -2.68549332e-03  -2.63038767e-03  -6.58269320e-03\n",
      "  -4.20389278e-03  -4.48831031e-03  -3.26097012e-04  -1.86012294e-02\n",
      "  -6.95900933e-04  -8.36616289e-03  -7.36152194e-03  -5.61395660e-03\n",
      "  -1.30487271e-02  -5.58212493e-03  -2.60864501e-03  -7.08669859e-06\n",
      "  -1.68336723e-02  -1.39045855e-02  -1.19888267e-04  -2.85773575e-02\n",
      "  -4.61112848e-03  -4.60589398e-03  -3.44849471e-03  -4.37314529e-03\n",
      "  -6.34481246e-03  -8.30386020e-03  -2.30461545e-03  -4.42108884e-03\n",
      "  -2.10408550e-02  -2.54063914e-03  -3.75411171e-03   4.28038154e-04\n",
      "  -6.41115103e-03  -8.25405004e-05  -2.41895858e-03  -4.57614334e-03\n",
      "  -9.06640384e-03  -2.65201717e-03  -6.48366194e-03  -3.86098027e-02\n",
      "  -4.59916005e-03  -6.03337772e-03  -3.39886872e-04  -8.29820987e-03\n",
      "  -9.65058338e-03  -8.06368794e-03  -1.44224591e-03   4.36391652e-04\n",
      "  -1.01124425e-03  -1.85147393e-03  -4.26015875e-04  -1.86770577e-02\n",
      "  -1.04656545e-02  -1.07856309e-02  -3.38988425e-03  -2.80714501e-03\n",
      "  -2.58402782e-03   5.06246215e-05  -1.19974092e-02  -6.49149250e-03\n",
      "  -5.36282496e-05  -5.82853053e-03   1.13491807e-03  -1.00471091e-03\n",
      "  -5.31378719e-05  -5.22226421e-03  -9.34056414e-04  -1.07171563e-02\n",
      "  -4.48867120e-03  -8.79462063e-03  -1.79384928e-02  -1.49386120e-03\n",
      "  -8.47248081e-03   1.01173449e-04  -3.31070251e-03  -3.06991242e-05\n",
      "  -2.78183236e-03  -5.42095397e-03  -5.96818654e-03  -6.10226358e-04\n",
      "  -1.84721593e-02  -1.17544690e-02  -2.74744909e-03  -7.14271422e-03\n",
      "  -2.36463547e-02  -2.67750514e-03  -5.01903705e-02  -7.17919925e-03\n",
      "   4.09615488e-04  -1.14396857e-02  -1.42900285e-03  -2.42408575e-03\n",
      "  -1.22837629e-03  -1.72872108e-03  -4.19900846e-03  -1.80320421e-04\n",
      "  -1.24325929e-02  -4.73637041e-03  -6.43671956e-03  -2.64362968e-03\n",
      "  -9.12927371e-03  -2.14082000e-04  -9.28010140e-03  -1.96347665e-03\n",
      "  -2.06710771e-03  -2.81975791e-03  -9.44401976e-03  -3.61520128e-04\n",
      "  -6.93952618e-03  -8.00284464e-03  -2.99723307e-03  -4.35063522e-03\n",
      "  -4.76893084e-03  -2.29127705e-03  -1.80643220e-02  -8.22505169e-03\n",
      "   1.56857859e-05  -1.90649331e-02  -3.33495275e-03  -9.41291102e-04\n",
      "  -8.22042301e-03  -4.50322317e-04  -2.59483187e-03  -4.29940876e-03\n",
      "   3.75297765e-04  -6.42723055e-04  -8.79982766e-03  -6.32400764e-03\n",
      "  -8.66231881e-03  -2.05037277e-03  -3.24572809e-03  -8.75206839e-04\n",
      "   3.65749380e-04  -6.79649180e-03  -5.00669878e-04   5.33468148e-04\n",
      "  -6.68058731e-03  -1.83266122e-03  -4.13127663e-03  -1.62158988e-03]\n",
      "[  4.34305810e-04   4.38172108e-04   5.54564642e-04   5.13720297e-05\n",
      "   1.14501559e-03   8.44468832e-06   9.22359468e-04   2.94250378e-04\n",
      "   1.71753636e-05   4.84689444e-05   9.21235478e-05   4.53612214e-04\n",
      "   9.47061926e-05   2.94260448e-04   1.52181849e-04   5.61428140e-04\n",
      "   6.35832475e-05   3.94332455e-04   2.56926811e-04   2.26223652e-04\n",
      "  -1.35361581e-04   2.28428587e-04  -2.65689072e-04   5.70312841e-04\n",
      "  -3.56108067e-04  -2.56787480e-05   3.72123701e-04   2.53203307e-05\n",
      "  -4.63730132e-04   6.10871532e-04   1.64710204e-04  -5.51366174e-05\n",
      "   6.08999107e-05  -1.82439617e-04   1.85074037e-04   3.13760218e-04\n",
      "   1.44379001e-05   1.40996563e-04   4.93777989e-05  -6.94994524e-05\n",
      "   3.54931137e-04  -5.64780967e-05   3.48308036e-04   1.47529875e-06\n",
      "   7.05717423e-04  -9.35178177e-05   8.85460991e-04   1.70446729e-04\n",
      "   8.08078097e-04   2.95852456e-04   2.36959371e-04   8.36234307e-04\n",
      "  -5.12678416e-05   2.44636991e-04   2.67879459e-05   2.32364269e-04\n",
      "   1.08983798e-03   1.39847689e-04   5.41430723e-04   1.52924229e-04\n",
      "   2.46653071e-04   4.04300401e-04   3.48572008e-04   3.12993361e-04\n",
      "   1.32100156e-03   2.19764793e-03   4.15062503e-04   1.59617557e-04\n",
      "   1.35614551e-04  -6.73440582e-06   9.72069218e-04   8.32526828e-04\n",
      "  -4.17642732e-04   1.61352538e-04   2.15244101e-04   1.61249875e-04\n",
      "   3.63971310e-04   4.42537828e-04   7.09983055e-04  -6.51469818e-05\n",
      "   2.19256781e-05   2.79002415e-04   2.56793894e-04   2.50328478e-04\n",
      "   2.08143829e-04   5.73531608e-04   4.74416884e-04   1.20745979e-04\n",
      "   1.51398606e-04   1.11021269e-04   7.34756031e-05  -1.07109163e-05\n",
      "  -9.85231673e-05   5.01351431e-04   2.00198294e-04   7.13130110e-04\n",
      "  -2.57743057e-04   7.87593075e-04   2.98941286e-05   5.67300827e-04\n",
      "   1.71657142e-04   8.38965352e-04   1.78281870e-03   3.95575662e-05\n",
      "  -1.58810930e-04   1.19285844e-03   8.06071985e-05   1.51375833e-04\n",
      "   2.19794606e-06  -4.80326271e-05   8.21982831e-05   3.18562597e-05\n",
      "  -4.54567111e-04  -9.54893330e-05   5.09500271e-04   5.47423144e-04\n",
      "   2.31949074e-04   2.15444845e-04   2.90559808e-04  -1.23654681e-04\n",
      "  -1.99593283e-04   5.57933236e-04   5.73757170e-05   2.16860004e-04\n",
      "   1.98979851e-05   1.13799870e-04  -8.60764412e-04   6.24603941e-04\n",
      "   1.08301858e-04   5.71762721e-05   6.38378609e-04   2.23201379e-04\n",
      "   2.58956396e-04   4.64942394e-04   8.88712704e-04   4.82623946e-05\n",
      "   2.50691461e-04   3.25444271e-04   1.01006334e-03   3.00752494e-04\n",
      "   8.50641227e-04   1.75383801e-04   3.52979434e-04   1.55272530e-04\n",
      "   2.29571000e-04   7.03897909e-04  -1.79044378e-04   3.73815739e-04\n",
      "  -3.47510322e-05   5.46436815e-04   3.69866844e-04  -2.13612715e-04\n",
      "   1.78952498e-04  -2.00731927e-04  -9.62524282e-05   2.41067813e-04\n",
      "   2.77893123e-04   4.47863771e-04   3.21721309e-05   4.38580319e-04\n",
      "   2.05998047e-04   6.52494084e-04   2.71209137e-05   5.57075313e-04\n",
      "   2.37506738e-05   1.18317512e-05  -3.64418782e-04  -1.52822598e-04\n",
      "   1.47403553e-04  -4.84653938e-05   1.83040815e-04   5.18808025e-04\n",
      "   2.94715137e-04  -2.95883183e-05   2.77294806e-04  -1.14321410e-04\n",
      "   7.62828713e-05   4.40403266e-04   3.15374091e-05   2.18776710e-04\n",
      "  -8.47457777e-05  -3.11082433e-04   2.84891285e-04  -2.43207367e-04\n",
      "   8.26861360e-04   2.14477914e-04   3.81019519e-04   5.76386286e-04\n",
      "   6.24076987e-04   7.20690179e-04   4.21845994e-04   1.66415761e-04\n",
      "   9.48414672e-05   1.71686593e-03   8.59392458e-05  -3.75402393e-04\n",
      "  -5.68868651e-04   3.95804062e-04   6.47605222e-04   4.94235464e-05]\n",
      "[  5.76214457e-04   2.66389194e-04   4.97773231e-04   4.12600872e-04\n",
      "  -1.83463155e-04   3.89260444e-04   2.33238185e-04   3.16079881e-04\n",
      "   1.39053314e-04   7.10014647e-05   2.54679908e-04   5.94521058e-04\n",
      "   2.52264115e-04  -7.36846487e-05   4.38579067e-04   1.02724691e-04\n",
      "   4.32175089e-04   3.04352725e-04   6.67144268e-05   1.72234213e-04\n",
      "  -3.33972828e-04   6.86524785e-04   3.66855413e-04   4.61407530e-04\n",
      "  -9.78392549e-04   7.92617902e-06   6.25232875e-04   4.16511088e-04\n",
      "  -3.04038171e-04   5.79745829e-05  -3.94648814e-04   9.00963933e-05\n",
      "   4.53131244e-04   1.90581006e-04   8.73523968e-05   1.97434885e-04\n",
      "   1.03603839e-03   5.05096687e-04  -4.25518694e-04  -4.32605855e-04\n",
      "  -7.57137896e-04  -2.38223671e-04   1.06860345e-04   1.28761007e-04\n",
      "   3.61448416e-04   6.62660983e-04   2.26869699e-04  -6.67344830e-06\n",
      "   6.29629998e-04   1.98093530e-05   6.23325352e-04   1.39103225e-03\n",
      "  -6.78780561e-05   2.67473661e-04   3.18809907e-04  -1.93749511e-04\n",
      "   1.46444960e-04   8.12061116e-05   2.75204511e-04   3.99849348e-04\n",
      "  -5.85085130e-04   5.38695604e-04   2.29721802e-04   1.27685242e-04\n",
      "   3.71972477e-04   8.06210737e-05  -2.52533442e-04   6.56181423e-04\n",
      "   1.18280062e-03   4.32783039e-04   1.14602452e-04   2.65213498e-03\n",
      "  -1.12458411e-05   6.45061780e-04   8.68332645e-05   9.56458825e-06\n",
      "   5.58303611e-04   6.60853111e-04   1.28657513e-04   3.06755275e-04\n",
      "   1.06557723e-04   2.33516737e-04   4.88393300e-04  -3.36294420e-06\n",
      "   1.73690874e-04   1.89095779e-04   6.41571241e-04   5.19799942e-04\n",
      "   2.28756413e-04  -1.36254566e-05   5.04851458e-04   4.62019176e-04\n",
      "  -1.10386994e-04   5.88919444e-04   2.05777396e-04  -3.54989606e-04\n",
      "  -1.31380468e-04   6.85950625e-04   1.64314595e-04   6.55227865e-04\n",
      "  -1.80835232e-05   3.32257914e-04   3.01506334e-05  -3.79277888e-04\n",
      "   2.31148675e-03  -4.03889317e-05   1.26324259e-04   7.42509554e-04\n",
      "   3.94112518e-04   7.30614702e-05  -4.36079099e-05   1.36209681e-04\n",
      "   9.75509101e-05   8.90235882e-04   5.62877627e-04   9.51283146e-05\n",
      "  -7.98357069e-04   1.15068426e-04  -2.11587860e-04   3.37147976e-05\n",
      "   5.83217246e-04  -5.04223863e-05   1.48944455e-04   1.06094369e-04\n",
      "   4.98141744e-04   1.67981270e-04   1.88659411e-03   5.27097436e-04\n",
      "   2.89502059e-04  -1.96670124e-04  -2.47785763e-04   3.14460049e-04\n",
      "  -2.38331020e-04   2.77044048e-04   1.08310999e-03   3.36646743e-04\n",
      "   2.64054688e-04  -2.40711761e-05  -1.18438482e-04  -4.63309698e-05\n",
      "   4.77822119e-04   1.85353667e-04   5.57055522e-04   4.59676550e-04\n",
      "   2.25798402e-04  -2.20078306e-04   1.12234929e-03   2.03571006e-04\n",
      "   7.28665618e-04   3.39593564e-04   9.03787906e-04   1.73874025e-04\n",
      "   1.44718238e-03   2.16514338e-04   1.32561210e-04  -4.94847191e-04\n",
      "   2.32431950e-04   8.59892389e-05  -3.51555180e-04  -3.01312568e-04\n",
      "   6.44269283e-04   7.41737458e-05   8.07214383e-05   2.41123285e-04\n",
      "   2.30225542e-05   1.41047218e-04   4.29200940e-04   1.62763186e-04\n",
      "   3.01458116e-04   5.87064598e-04   3.48016532e-04   4.13045113e-04\n",
      "   3.73525574e-04   6.07437745e-04   1.91840722e-04  -9.88554530e-05\n",
      "   1.46137332e-04   5.49579621e-04   2.05823773e-04  -3.60386592e-04\n",
      "   2.19766851e-04   9.18095466e-04   2.96551207e-05   3.83752951e-04\n",
      "   8.02355935e-04  -2.69880675e-05   1.46250625e-03  -1.72344546e-04\n",
      "   4.96706052e-04  -3.46795860e-04   3.99028475e-04  -1.19721389e-03\n",
      "   6.66463748e-04   5.97888429e-04   8.99960345e-04   1.51934277e-04\n",
      "  -2.92294513e-04   4.29115171e-04   2.01614981e-04   4.60107432e-04]\n",
      "[  5.83585468e-04   3.23254993e-04  -1.69846904e-03   4.79663955e-04\n",
      "  -9.65455110e-05  -1.17646174e-04   6.88948494e-04   1.55428002e-04\n",
      "   7.60138966e-04  -5.13391569e-04  -4.15432092e-04   3.50264600e-04\n",
      "  -1.31210149e-03  -1.13593834e-03   1.56117429e-04   1.62166500e-04\n",
      "  -1.56615418e-03   5.57283754e-04  -1.98253721e-04  -3.26106703e-04\n",
      "  -1.95990506e-04  -5.23841474e-04  -4.54023015e-04  -4.29402717e-04\n",
      "   3.28675145e-04   3.49575101e-04  -4.53934132e-04   9.01723455e-04\n",
      "   2.53524282e-03   6.83027611e-05   1.29518870e-04   3.34303477e-04\n",
      "   5.68707532e-04  -5.78154461e-04   4.81836702e-04   2.97932478e-04\n",
      "  -3.99742182e-03   1.98263035e-04   5.05796110e-04   4.19266900e-04\n",
      "   5.75084705e-04   1.61297480e-03   3.11816169e-04   2.85838585e-04\n",
      "   6.56904958e-05  -1.17289950e-04  -1.14718860e-03  -7.38778792e-04\n",
      "   3.03916004e-05   1.58201714e-04   2.92305485e-05  -6.41326869e-06\n",
      "   5.85694157e-04  -1.09471417e-04   1.07984792e-03  -2.18982641e-05\n",
      "   1.41766490e-04  -7.12963811e-04  -6.21318686e-05  -4.46316437e-04\n",
      "   8.03220668e-04   3.42868792e-04   9.64844658e-05  -2.47213960e-04\n",
      "  -1.32581918e-04  -1.67669356e-03   2.29286685e-04   6.56853605e-04\n",
      "  -1.22508511e-03   8.23096489e-04   6.06642512e-04  -1.61638658e-03\n",
      "   2.68704374e-04  -1.84447621e-04   4.89109625e-05  -5.09823949e-05\n",
      "   1.83500539e-04   5.41499991e-04   4.15355840e-04  -4.34664020e-04\n",
      "   9.23135027e-04   7.58120441e-05  -7.67869293e-04   3.75592426e-05\n",
      "   2.87072180e-04  -3.76502954e-04   5.46757830e-04  -3.74295400e-03\n",
      "   1.34598964e-03   4.44295671e-04  -4.67777718e-04  -3.07774666e-04\n",
      "  -9.55565629e-05   1.91327665e-04   1.32777321e-04   4.45821934e-04\n",
      "  -1.22343446e-03  -7.72800013e-06  -5.73020588e-05  -3.02405184e-04\n",
      "   1.92364430e-04   8.62612651e-05   3.74521303e-04   2.67323980e-04\n",
      "  -5.49434102e-04   5.38481516e-04   3.77742399e-05   7.68337268e-05\n",
      "   9.49848472e-05   1.44887366e-03   2.93960649e-04  -6.86930784e-04\n",
      "  -4.13943315e-03   2.83023110e-05  -2.80938088e-03   2.28646531e-04\n",
      "   3.01007443e-04  -1.43965799e-03   8.87706236e-04  -1.08874554e-03\n",
      "  -2.74190959e-03  -7.59841700e-04   1.48631327e-04  -6.70963025e-04\n",
      "   2.40290916e-04   7.63410295e-04  -1.43277668e-03  -5.66649134e-04\n",
      "   9.95858340e-04  -6.74880284e-04  -1.14464790e-04   4.55414818e-04\n",
      "  -2.70326418e-04  -3.92179424e-03   3.99058044e-05  -1.82024518e-03\n",
      "   4.73049178e-04   4.76130401e-04   1.44188618e-03  -5.44863055e-04\n",
      "  -4.42152348e-04   3.46185756e-04   6.68366149e-04   1.09044858e-03\n",
      "   1.64072859e-04   1.67175441e-03   2.00513441e-05   8.97053978e-04\n",
      "  -1.92328682e-03   4.09430300e-04  -1.55759219e-03  -3.57127486e-04\n",
      "  -1.85729505e-03   2.98206485e-03  -1.68224171e-04   5.93416509e-04\n",
      "   1.98591314e-03  -2.85239279e-04   2.98986008e-04  -9.51512775e-04\n",
      "   2.13795167e-04  -6.92894449e-04  -1.58728260e-04   2.78775318e-04\n",
      "  -3.35977762e-04   9.89344670e-04  -1.68102648e-04   3.87916109e-04\n",
      "   3.61354672e-04   1.12574948e-04   4.08419757e-04   2.55679042e-04\n",
      "   2.31986196e-04   8.05759337e-05  -4.66037542e-03   1.02760619e-03\n",
      "   1.22498872e-03   1.42581400e-03  -1.47688610e-03  -1.56527385e-03\n",
      "   1.24227357e-04  -4.26402228e-04   1.76538932e-04  -3.10119917e-03\n",
      "  -5.69704734e-03   1.38645890e-04  -4.05736384e-04   9.42755083e-04\n",
      "  -1.54914695e-03   4.69624327e-04   4.65931720e-04  -2.57607619e-03\n",
      "   7.88208854e-04  -3.52718314e-04  -1.52786568e-04  -2.00565881e-03\n",
      "  -4.11404704e-04  -4.08471283e-03   6.85908890e-04   8.34632257e-04]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "'''\n",
    "データの生成\n",
    "'''\n",
    "mnist = datasets.fetch_mldata('MNIST original', data_home='.')\n",
    "\n",
    "n = len(mnist.data)\n",
    "N = 10000  # MNISTの一部を使う\n",
    "train_size = 0.8\n",
    "indices = np.random.permutation(range(n))[:N]  # ランダムにN枚を選択\n",
    "\n",
    "X = mnist.data[indices]\n",
    "y = mnist.target[indices]\n",
    "Y = np.eye(10)[y.astype(int)]  # 1-of-K 表現に変換\n",
    "\n",
    "X_train, X_test, Y_train, Y_test =\\\n",
    "    train_test_split(X, Y, train_size=train_size)\n",
    "\n",
    "'''\n",
    "モデル設定\n",
    "'''\n",
    "n_in = len(X[0])  # 784\n",
    "n_hidden = 200\n",
    "n_out = len(Y[0])  # 10\n",
    "\n",
    "\n",
    "def prelu(x, alpha):\n",
    "    return tf.maximum(tf.zeros(tf.shape(x)), x) \\\n",
    "        + alpha * tf.minimum(tf.zeros(tf.shape(x)), x)\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, n_in])\n",
    "t = tf.placeholder(tf.float32, shape=[None, n_out])\n",
    "\n",
    "# 入力層 - 隠れ層\n",
    "W0 = tf.Variable(tf.truncated_normal([n_in, n_hidden], stddev=0.01))\n",
    "b0 = tf.Variable(tf.zeros([n_hidden]))\n",
    "alpha0 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h0 = prelu(tf.matmul(x, W0) + b0, alpha0)\n",
    "\n",
    "# 隠れ層 - 隠れ層\n",
    "W1 = tf.Variable(tf.truncated_normal([n_hidden, n_hidden], stddev=0.01))\n",
    "b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "alpha1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h1 = prelu(tf.matmul(h0, W1) + b1, alpha1)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([n_hidden, n_hidden], stddev=0.01))\n",
    "b2 = tf.Variable(tf.zeros([n_hidden]))\n",
    "alpha2 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h2 = prelu(tf.matmul(h1, W2) + b2, alpha2)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([n_hidden, n_hidden], stddev=0.01))\n",
    "b3 = tf.Variable(tf.zeros([n_hidden]))\n",
    "alpha3 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h3 = prelu(tf.matmul(h2, W3) + b3, alpha3)\n",
    "\n",
    "# 隠れ層 - 出力層\n",
    "W4 = tf.Variable(tf.truncated_normal([n_hidden, n_out], stddev=0.01))\n",
    "b4 = tf.Variable(tf.zeros([n_out]))\n",
    "y = tf.nn.softmax(tf.matmul(h3, W4) + b4)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(t * tf.log(y),\n",
    "                               reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(t, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "'''\n",
    "モデル学習\n",
    "'''\n",
    "epochs = 50\n",
    "batch_size = 200\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "n_batches = (int)(N * train_size) // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    X_, Y_ = shuffle(X_train, Y_train)\n",
    "\n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        sess.run(train_step, feed_dict={\n",
    "            x: X_[start:end],\n",
    "            t: Y_[start:end]\n",
    "        })\n",
    "\n",
    "    # 訓練データに対する学習の進み具合を出力\n",
    "    loss = cross_entropy.eval(session=sess, feed_dict={\n",
    "        x: X_,\n",
    "        t: Y_\n",
    "    })\n",
    "    acc = accuracy.eval(session=sess, feed_dict={\n",
    "        x: X_,\n",
    "        t: Y_\n",
    "    })\n",
    "    print('epoch:', epoch, ' loss:', loss, ' accuracy:', acc)\n",
    "\n",
    "'''\n",
    "予測精度の評価\n",
    "'''\n",
    "accuracy_rate = accuracy.eval(session=sess, feed_dict={\n",
    "    x: X_test,\n",
    "    t: Y_test\n",
    "})\n",
    "print('accuracy: ', accuracy_rate)\n",
    "\n",
    "# 学習後の alpha の値を確認\n",
    "print(sess.run(alpha0))\n",
    "print(sess.run(alpha1))\n",
    "print(sess.run(alpha2))\n",
    "print(sess.run(alpha3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
