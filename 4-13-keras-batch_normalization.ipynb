{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Keras によるコーディング</h2>\n",
       "<ul>\n",
       "  <li>drop 0.5</li>\n",
       "  <li>activation: relu</li>\n",
       "  <li>hidden layer: 3</li>\n",
       "  <li>early stopping</li>\n",
       "  <li>batch normalization</li>\n",
       "</ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<h2>Keras によるコーディング</h2>\n",
    "<ul>\n",
    "  <li>drop 0.5</li>\n",
    "  <li>activation: relu</li>\n",
    "  <li>hidden layer: 3</li>\n",
    "  <li>early stopping</li>\n",
    "  <li>batch normalization</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/200\n",
      "16000/16000 [==============================] - 2s - loss: 1.5201 - acc: 0.5049 - val_loss: 0.6337 - val_acc: 0.8385\n",
      "Epoch 2/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.6873 - acc: 0.7823 - val_loss: 0.3708 - val_acc: 0.8958\n",
      "Epoch 3/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.5234 - acc: 0.8396 - val_loss: 0.2812 - val_acc: 0.9170\n",
      "Epoch 4/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.4422 - acc: 0.8667 - val_loss: 0.2717 - val_acc: 0.9165\n",
      "Epoch 5/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.3915 - acc: 0.8805 - val_loss: 0.2442 - val_acc: 0.9243\n",
      "Epoch 6/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.3630 - acc: 0.8889 - val_loss: 0.2108 - val_acc: 0.9340\n",
      "Epoch 7/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.3337 - acc: 0.8984 - val_loss: 0.2035 - val_acc: 0.9365\n",
      "Epoch 8/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.3060 - acc: 0.9071 - val_loss: 0.1905 - val_acc: 0.9405\n",
      "Epoch 9/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.2873 - acc: 0.9134 - val_loss: 0.1799 - val_acc: 0.9433\n",
      "Epoch 10/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.2726 - acc: 0.9194 - val_loss: 0.1715 - val_acc: 0.9465\n",
      "Epoch 11/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.2490 - acc: 0.9251 - val_loss: 0.1707 - val_acc: 0.9472\n",
      "Epoch 12/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.2323 - acc: 0.9279 - val_loss: 0.1715 - val_acc: 0.9490\n",
      "Epoch 13/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.2321 - acc: 0.9324 - val_loss: 0.1642 - val_acc: 0.9505\n",
      "Epoch 14/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.2109 - acc: 0.9381 - val_loss: 0.1526 - val_acc: 0.9505\n",
      "Epoch 15/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.2068 - acc: 0.9377 - val_loss: 0.1457 - val_acc: 0.9525\n",
      "Epoch 16/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1911 - acc: 0.9414 - val_loss: 0.1413 - val_acc: 0.9588\n",
      "Epoch 17/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1808 - acc: 0.9465 - val_loss: 0.1392 - val_acc: 0.9570\n",
      "Epoch 18/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1874 - acc: 0.9441 - val_loss: 0.1503 - val_acc: 0.9568\n",
      "Epoch 19/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1693 - acc: 0.9474 - val_loss: 0.1470 - val_acc: 0.9567\n",
      "Epoch 20/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1623 - acc: 0.9504 - val_loss: 0.1376 - val_acc: 0.9562\n",
      "Epoch 21/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1554 - acc: 0.9525 - val_loss: 0.1468 - val_acc: 0.9562\n",
      "Epoch 22/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1490 - acc: 0.9556 - val_loss: 0.1399 - val_acc: 0.9600\n",
      "Epoch 23/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1410 - acc: 0.9574 - val_loss: 0.1374 - val_acc: 0.9602\n",
      "Epoch 24/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1372 - acc: 0.9562 - val_loss: 0.1414 - val_acc: 0.9618\n",
      "Epoch 25/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1364 - acc: 0.9582 - val_loss: 0.1391 - val_acc: 0.9588\n",
      "Epoch 26/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1255 - acc: 0.9601 - val_loss: 0.1508 - val_acc: 0.9562\n",
      "Epoch 27/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1299 - acc: 0.9594 - val_loss: 0.1457 - val_acc: 0.9592\n",
      "Epoch 28/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1271 - acc: 0.9599 - val_loss: 0.1332 - val_acc: 0.9648\n",
      "Epoch 29/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1161 - acc: 0.9638 - val_loss: 0.1327 - val_acc: 0.9638\n",
      "Epoch 30/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1111 - acc: 0.9669 - val_loss: 0.1240 - val_acc: 0.9675\n",
      "Epoch 31/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1139 - acc: 0.9639 - val_loss: 0.1472 - val_acc: 0.9638\n",
      "Epoch 32/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1065 - acc: 0.9675 - val_loss: 0.1426 - val_acc: 0.9620\n",
      "Epoch 33/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1039 - acc: 0.9666 - val_loss: 0.1257 - val_acc: 0.9668\n",
      "Epoch 34/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1035 - acc: 0.9671 - val_loss: 0.1318 - val_acc: 0.9638\n",
      "Epoch 35/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.1003 - acc: 0.9691 - val_loss: 0.1529 - val_acc: 0.9605\n",
      "Epoch 36/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.0954 - acc: 0.9696 - val_loss: 0.1351 - val_acc: 0.9628\n",
      "Epoch 37/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.0934 - acc: 0.9698 - val_loss: 0.1317 - val_acc: 0.9655\n",
      "Epoch 38/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.0942 - acc: 0.9733 - val_loss: 0.1329 - val_acc: 0.9675\n",
      "Epoch 39/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.0842 - acc: 0.9730 - val_loss: 0.1337 - val_acc: 0.9655\n",
      "Epoch 40/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.0855 - acc: 0.9737 - val_loss: 0.1346 - val_acc: 0.9628\n",
      "Epoch 41/200\n",
      "16000/16000 [==============================] - 1s - loss: 0.0872 - acc: 0.9723 - val_loss: 0.1320 - val_acc: 0.9660\n",
      "Epoch 00040: early stopping\n",
      "10000/10000 [==============================] - 0s     \n",
      "[0.12327821721322835, 0.9667]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "'''\n",
    "データの生成\n",
    "'''\n",
    "mnist = datasets.fetch_mldata('MNIST original', data_home='.')\n",
    "\n",
    "n = len(mnist.data)\n",
    "N = 30000  # MNISTの一部を使う\n",
    "N_train = 20000\n",
    "N_validation = 4000\n",
    "indices = np.random.permutation(range(n))[:N]  # ランダムにN枚を選択\n",
    "\n",
    "X = mnist.data[indices]\n",
    "X = X / 255.0\n",
    "X = X - X.mean(axis=1).reshape(len(X), 1)\n",
    "y = mnist.target[indices]\n",
    "Y = np.eye(10)[y.astype(int)]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = \\\n",
    "    train_test_split(X, Y, train_size=N_train)\n",
    "X_train, X_validation, Y_train, Y_validation = \\\n",
    "    train_test_split(X_train, Y_train, test_size=N_validation)\n",
    "\n",
    "'''\n",
    "モデル設定\n",
    "'''\n",
    "n_in = len(X[0])  # 784\n",
    "n_hiddens = [200, 200, 200]\n",
    "n_out = len(Y[0])  # 10\n",
    "p_keep = 0.5\n",
    "activation = 'relu'\n",
    "\n",
    "\n",
    "def weight_variable(shape, name=None):\n",
    "    return np.sqrt(2.0 / shape[0]) * np.random.normal(size=shape)\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "model = Sequential()\n",
    "for i, input_dim in enumerate(([n_in] + n_hiddens)[:-1]):\n",
    "    model.add(Dense(n_hiddens[i], input_dim=input_dim,\n",
    "                    kernel_initializer=weight_variable))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(p_keep))\n",
    "\n",
    "model.add(Dense(n_out, kernel_initializer=weight_variable))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "'''\n",
    "モデル学習\n",
    "'''\n",
    "epochs = 200\n",
    "batch_size = 200\n",
    "\n",
    "hist = model.fit(X_train, Y_train, epochs=epochs,\n",
    "                 batch_size=batch_size,\n",
    "                 validation_data=(X_validation, Y_validation),\n",
    "                 callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "'''\n",
    "予測精度の評価\n",
    "'''\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe95c480da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "学習の進み具合を可視化\n",
    "'''\n",
    "val_acc = hist.history['val_acc']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "fig = plt.figure()\n",
    "plt.plot(range(len(val_loss)), val_loss, label='loss', color='black')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
