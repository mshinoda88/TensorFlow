{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>TensorFlow による推奨コーディングの作法</h2>\n",
       "<ul>\n",
       "  <li>DNN というクラス導入で、汎用性の高いAPI化</li>\n",
       "</ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<h2>TensorFlow による推奨コーディングの作法</h2>\n",
    "<ul>\n",
    "  <li>DNN というクラス導入で、汎用性の高いAPI化</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 2.2707  accuracy: 0.33775\n",
      "epoch: 1  loss: 2.02816  accuracy: 0.45625\n",
      "epoch: 2  loss: 1.02788  accuracy: 0.660125\n",
      "epoch: 3  loss: 0.76394  accuracy: 0.73\n",
      "epoch: 4  loss: 0.557575  accuracy: 0.836375\n",
      "epoch: 5  loss: 0.459215  accuracy: 0.8665\n",
      "epoch: 6  loss: 0.395595  accuracy: 0.886375\n",
      "epoch: 7  loss: 0.347925  accuracy: 0.89925\n",
      "epoch: 8  loss: 0.301812  accuracy: 0.911375\n",
      "epoch: 9  loss: 0.277048  accuracy: 0.91975\n",
      "epoch: 10  loss: 0.254636  accuracy: 0.928625\n",
      "epoch: 11  loss: 0.228701  accuracy: 0.934875\n",
      "epoch: 12  loss: 0.211891  accuracy: 0.93975\n",
      "epoch: 13  loss: 0.196632  accuracy: 0.944125\n",
      "epoch: 14  loss: 0.177651  accuracy: 0.948\n",
      "epoch: 15  loss: 0.168541  accuracy: 0.950125\n",
      "epoch: 16  loss: 0.158311  accuracy: 0.95275\n",
      "epoch: 17  loss: 0.14682  accuracy: 0.956375\n",
      "epoch: 18  loss: 0.136613  accuracy: 0.96025\n",
      "epoch: 19  loss: 0.129347  accuracy: 0.962375\n",
      "epoch: 20  loss: 0.120389  accuracy: 0.96575\n",
      "epoch: 21  loss: 0.112493  accuracy: 0.967125\n",
      "epoch: 22  loss: 0.119393  accuracy: 0.965125\n",
      "epoch: 23  loss: 0.106341  accuracy: 0.968125\n",
      "epoch: 24  loss: 0.0935826  accuracy: 0.973875\n",
      "epoch: 25  loss: 0.0870727  accuracy: 0.974625\n",
      "epoch: 26  loss: 0.0806585  accuracy: 0.977125\n",
      "epoch: 27  loss: 0.0795582  accuracy: 0.978875\n",
      "epoch: 28  loss: 0.0737057  accuracy: 0.97925\n",
      "epoch: 29  loss: 0.0687838  accuracy: 0.980125\n",
      "accuracy:  0.9385\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "\n",
    "class DNN(object):\n",
    "    def __init__(self, n_in, n_hiddens, n_out):\n",
    "        self.n_in = n_in\n",
    "        self.n_hiddens = n_hiddens\n",
    "        self.n_out = n_out\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        self._x = None\n",
    "        self._t = None,\n",
    "        self._keep_prob = None\n",
    "        self._sess = None\n",
    "        self._history = {\n",
    "            'accuracy': [],\n",
    "            'loss': []\n",
    "        }\n",
    "        self.accurary_op = None\n",
    "\n",
    "    def weight_variable(self, shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def bias_variable(self, shape):\n",
    "        initial = tf.zeros(shape)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def inference(self, x, keep_prob):\n",
    "        # 入力層 - 隠れ層、隠れ層 - 隠れ層\n",
    "        for i, n_hidden in enumerate(self.n_hiddens):\n",
    "            if i == 0:\n",
    "                input = x\n",
    "                input_dim = self.n_in\n",
    "            else:\n",
    "                input = output\n",
    "                input_dim = self.n_hiddens[i-1]\n",
    "\n",
    "            self.weights.append(self.weight_variable([input_dim, n_hidden]))\n",
    "            self.biases.append(self.bias_variable([n_hidden]))\n",
    "\n",
    "            h = tf.nn.relu(tf.matmul(\n",
    "                input, self.weights[-1]) + self.biases[-1])\n",
    "            output = tf.nn.dropout(h, keep_prob)\n",
    "\n",
    "        # 隠れ層 - 出力層\n",
    "        self.weights.append(\n",
    "            self.weight_variable([self.n_hiddens[-1], self.n_out]))\n",
    "        self.biases.append(self.bias_variable([self.n_out]))\n",
    "\n",
    "        y = tf.nn.softmax(tf.matmul(\n",
    "            output, self.weights[-1]) + self.biases[-1])\n",
    "        return y\n",
    "\n",
    "    def loss(self, y, t):\n",
    "        cross_entropy = tf.reduce_mean(-tf.reduce_sum(t * tf.log(y),\n",
    "                                       reduction_indices=[1]))\n",
    "        return cross_entropy\n",
    "\n",
    "    def training(self, loss):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "        train_step = optimizer.minimize(loss)\n",
    "        return train_step\n",
    "\n",
    "    def accuracy(self, y, t):\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(t, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        return accuracy\n",
    "\n",
    "    def fit(self, X_train, Y_train,\n",
    "            nb_epoch=100, batch_size=100, p_keep=0.5,\n",
    "            verbose=1):\n",
    "        x = tf.placeholder(tf.float32, shape=[None, self.n_in])\n",
    "        t = tf.placeholder(tf.float32, shape=[None, self.n_out])\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "        self._x = x\n",
    "        self._t = t\n",
    "        self._keep_prob = keep_prob\n",
    "\n",
    "        y = self.inference(x, keep_prob)\n",
    "        loss = self.loss(y, t)\n",
    "        train_step = self.training(loss)\n",
    "        accuracy = self.accuracy(y, t)\n",
    "        self.accurary_op = accuracy\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "\n",
    "        self._sess = sess\n",
    "\n",
    "        N_train = len(X_train)\n",
    "        n_batches = N_train // batch_size\n",
    "\n",
    "        for epoch in range(nb_epoch):\n",
    "            X_, Y_ = shuffle(X_train, Y_train)\n",
    "\n",
    "            for i in range(n_batches):\n",
    "                start = i * batch_size\n",
    "                end = start + batch_size\n",
    "\n",
    "                sess.run(train_step, feed_dict={\n",
    "                    x: X_[start:end],\n",
    "                    t: Y_[start:end],\n",
    "                    keep_prob: p_keep\n",
    "                })\n",
    "            loss_ = loss.eval(session=sess, feed_dict={\n",
    "                x: X_train,\n",
    "                t: Y_train,\n",
    "                keep_prob: 1.0\n",
    "            })\n",
    "            accuracy_ = accuracy.eval(session=sess, feed_dict={\n",
    "                x: X_train,\n",
    "                t: Y_train,\n",
    "                keep_prob: 1.0\n",
    "            })\n",
    "            self._history['loss'].append(loss_)\n",
    "            self._history['accuracy'].append(accuracy_)\n",
    "\n",
    "            if verbose:\n",
    "                print('epoch:', epoch,\n",
    "                      ' loss:', loss_,\n",
    "                      ' accuracy:', accuracy_)\n",
    "\n",
    "        return self._history\n",
    "\n",
    "    def evaluate(self, X_test, Y_test):\n",
    "        return self.accurary_op.eval(session=self._sess, feed_dict={\n",
    "            self._x: X_test,\n",
    "            self._t: Y_test,\n",
    "            self._keep_prob: 1.0\n",
    "        })\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    '''\n",
    "    データの生成\n",
    "    '''\n",
    "    mnist = datasets.fetch_mldata('MNIST original', data_home='.')\n",
    "\n",
    "    n = len(mnist.data)\n",
    "    N = 10000  # MNISTの一部を使う\n",
    "    indices = np.random.permutation(range(n))[:N]  # ランダムにN枚を選択\n",
    "\n",
    "    X = mnist.data[indices]\n",
    "    y = mnist.target[indices]\n",
    "    Y = np.eye(10)[y.astype(int)]  # 1-of-K 表現に変換\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8)\n",
    "\n",
    "    '''\n",
    "    モデル設定\n",
    "    '''\n",
    "    model = DNN(n_in=len(X[0]),\n",
    "                n_hiddens=[200, 200, 200],\n",
    "                n_out=len(Y[0]))\n",
    "\n",
    "    '''\n",
    "    モデル学習\n",
    "    '''\n",
    "    model.fit(X_train, Y_train,\n",
    "              nb_epoch=30,\n",
    "              batch_size=200,\n",
    "              p_keep=0.5)\n",
    "\n",
    "    '''\n",
    "    予測精度の評価\n",
    "    '''\n",
    "    accuracy = model.evaluate(X_test, Y_test)\n",
    "    print('accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
